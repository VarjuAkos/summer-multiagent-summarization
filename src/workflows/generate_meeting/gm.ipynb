{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "def load_markdown_to_str(file_path):\n",
    "\twith open(file_path, 'r', encoding='utf-8') as md_file:\n",
    "\t\tmarkdown_content = md_file.read()\n",
    "\treturn markdown_content\n",
    "\n",
    "def load_latest_sprint_status(base_path):\n",
    "    \"\"\"\n",
    "    Find the latest sprint directory and load the project-sprint-status.md file.\n",
    "    \n",
    "    Args:\n",
    "    base_path (str): Path to the directory containing sprint folders.\n",
    "    \n",
    "    Returns:\n",
    "    str: Content of the project-sprint-status.md file from the latest sprint.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # List all directories in the base path\n",
    "        directories = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "        \n",
    "        # Filter and sort sprint directories\n",
    "        sprint_dirs = sorted([d for d in directories if d.startswith('sprint') and d[6:].isdigit()],\n",
    "                             key=lambda x: int(x[6:]),\n",
    "                             reverse=True)\n",
    "        \n",
    "        if not sprint_dirs:\n",
    "            return \"No sprint directories found.\"\n",
    "        \n",
    "        # Get the latest sprint directory\n",
    "        latest_sprint = sprint_dirs[0]\n",
    "        sprint_path = os.path.join(base_path, latest_sprint)\n",
    "        \n",
    "        # Look for project-sprint-status.md in the latest sprint directory\n",
    "        status_file = os.path.join(sprint_path, 'project-sprint-status.md')\n",
    "        \n",
    "        if os.path.exists(status_file):\n",
    "            with open(status_file, 'r', encoding='utf-8') as f:\n",
    "                return f.read()\n",
    "        else:\n",
    "            return f\"project-sprint-status.md not found in {latest_sprint}.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "    \n",
    "    \n",
    "def load_latest_sprint_backlog(base_path):\n",
    "    \"\"\"\n",
    "    Find the latest sprint directory and load the project-sprint-backlog.json file.\n",
    "    \n",
    "    Args:\n",
    "    base_path (str): Path to the directory containing sprint folders.\n",
    "    \n",
    "    Returns:\n",
    "    dict: Content of the project-sprint-backlog.json file from the latest sprint.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # List all directories in the base path\n",
    "        directories = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "        \n",
    "        # Filter and sort sprint directories\n",
    "        sprint_dirs = sorted([d for d in directories if d.startswith('sprint') and d[6:].isdigit()],\n",
    "                             key=lambda x: int(x[6:]),\n",
    "                             reverse=True)\n",
    "        \n",
    "        if not sprint_dirs:\n",
    "            return {\"error\": \"No sprint directories found.\"}\n",
    "        \n",
    "        # Get the latest sprint directory\n",
    "        latest_sprint = sprint_dirs[0]\n",
    "        sprint_path = os.path.join(base_path, latest_sprint)\n",
    "        \n",
    "        # Look for project-sprint-backlog.json in the latest sprint directory\n",
    "        backlog_file = os.path.join(sprint_path, 'project-sprint-backlog.json')\n",
    "        \n",
    "        if os.path.exists(backlog_file):\n",
    "            with open(backlog_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        else:\n",
    "            return {\"error\": f\"project-sprint-backlog.json not found in {latest_sprint}.\"}\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"An error occurred: {str(e)}\"}\n",
    "\n",
    "def export_transcript(state, folder_path):\n",
    "    # Create the folder if it doesn't exist\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    id = len(files) + 1\n",
    "\n",
    "    transcript = state[\"transcript\"]\n",
    "\n",
    "    if \"sprint planning\" in state[\"meeting_type\"].lower():\n",
    "        meeting_type = \"sprint_planning\"\n",
    "    elif \"daily scrum\" in state[\"meeting_type\"].lower():\n",
    "        meeting_type = \"daily_scrum\"\n",
    "    elif \"sprint review\" in state[\"meeting_type\"].lower():\n",
    "        meeting_type = \"sprint_review\"\n",
    "    elif \"sprint retrospective\" in state[\"meeting_type\"].lower():\n",
    "        meeting_type = \"sprint_retrospective\"\n",
    "    else:\n",
    "        meeting_type = \"unknown\"\n",
    "    \n",
    "    filename = meeting_type + \"_\" + str(id) + \".txt\"\n",
    "    \n",
    "    os.makedirs(os.path.join(folder_path), exist_ok=True)\n",
    "    \n",
    "    \n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Write the string to a text file\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(transcript)\n",
    "\n",
    "def export_state(state, folder_path, filename):\n",
    "    # Create the folder if it doesn't exist\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    id = len(files) + 1\n",
    "    \n",
    "    filename = filename+str(id)+\".json\"\n",
    "    \n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Write the state dict to a JSON file\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(state, f, indent=4)\n",
    "\n",
    "def load_txt_to_str(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as txt_file:\n",
    "        text_content = txt_file.read()\n",
    "    return text_content\n",
    "\n",
    "def load_from_json(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a JSON file.\n",
    "    \n",
    "    Args:\n",
    "    file_path (str): Path to the JSON file.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing the loaded JSON data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return {}\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in file {file_path}\")\n",
    "        return {}\n",
    "    \n",
    "def render_mermaid_diagram(diagram_code: str) -> str:\n",
    "    # Encode the Mermaid code\n",
    "    encoded_diagram = base64.b64encode(diagram_code.encode('utf-8')).decode('utf-8')\n",
    "    \n",
    "    # Make a request to the Mermaid rendering service\n",
    "    url = f\"https://mermaid.ink/img/{encoded_diagram}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Return the URL of the rendered image\n",
    "        return url\n",
    "    else:\n",
    "        # If rendering failed, return the original Mermaid code\n",
    "        return f\"```mermaid\\n{diagram_code}\\n```\"\n",
    "    \n",
    "def format_mermaid(input_string):\n",
    "    # Step 1: Remove redundant \"```mermaid\" at the start and end\n",
    "    cleaned_string = input_string.replace('```mermaid', '').replace('```', '')\n",
    "    \n",
    "    # Step 2: Replace escaped newlines with actual newlines\n",
    "    formatted_string = cleaned_string.replace(r'\\n', '\\n')\n",
    "    \n",
    "    # Step 3: Strip any leading/trailing whitespace\n",
    "    formatted_string = formatted_string.strip()\n",
    "\n",
    "    return formatted_string\t\n",
    "\n",
    "\n",
    "def export_meeting_history(state, output_file='meeting_history.json'):\n",
    "    \"\"\"\n",
    "    Export the meeting history to a JSON file.\n",
    "    \n",
    "    Args:\n",
    "    state (dict): The state dictionary containing the meeting history.\n",
    "    output_file (str): The name of the output file. Defaults to 'meeting_history.json'.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    meeting_history = state[\"meeting_history\"]\n",
    "    \n",
    "    # Ensure meeting_history is a list\n",
    "    if not isinstance(meeting_history, list):\n",
    "        meeting_history = [meeting_history]\n",
    "    \n",
    "    try:\n",
    "        with open(output_file, 'w') as file:\n",
    "            json.dump(meeting_history, file, indent=2)\n",
    "        print(f\"Meeting history exported successfully to {output_file}\")\n",
    "    except IOError:\n",
    "        print(f\"Error: Unable to write to file {output_file}\")\n",
    "\n",
    "    return state  # Return the state to maintain consistency with your workflow\n",
    "\n",
    "\n",
    "def manage_sprint_folders(state, project_folder):\n",
    "    \"\"\"\n",
    "    Manages sprint folders based on the meeting type.\n",
    "    Creates a new sprint folder if necessary and adds required files.\n",
    "    \n",
    "    :param state: The current state dictionary\n",
    "    :param project_folder: Path to the project folder\n",
    "    :return: Updated state with new sprint information\n",
    "    \"\"\"\n",
    "    if \"planning\" in state.get(\"meeting_type\", \"\").lower() or \"plan\" in state.get(\"meeting_type\", \"\").lower():\n",
    "        # List all directories in the project folder\n",
    "        directories = [d for d in os.listdir(project_folder) if os.path.isdir(os.path.join(project_folder, d))]\n",
    "        \n",
    "        # Filter and find the highest sprint number\n",
    "        sprint_numbers = [int(re.findall(r'\\d+', d)[0]) for d in directories if d.startswith(\"sprint\") and re.findall(r'\\d+', d)]\n",
    "        \n",
    "        if sprint_numbers:\n",
    "            new_sprint_number = max(sprint_numbers) + 1\n",
    "        else:\n",
    "            new_sprint_number = 1\n",
    "        \n",
    "        # Create new sprint folder\n",
    "        new_sprint_folder = os.path.join(project_folder, f\"sprint{new_sprint_number}\")\n",
    "        os.makedirs(new_sprint_folder, exist_ok=True)\n",
    "        \n",
    "        # Create project_sprint_status.md\n",
    "        status_file_path = os.path.join(new_sprint_folder, \"project_sprint_status.md\")\n",
    "        with open(status_file_path, 'w') as status_file:\n",
    "            status_file.write(f\"# Sprint {new_sprint_number} Status\\n\\nStatus details will be updated here.\")\n",
    "        \n",
    "        # Create project_sprint_backlog.json\n",
    "        backlog_file_path = os.path.join(new_sprint_folder, \"project_sprint_backlog.json\")\n",
    "        initial_backlog = {}\n",
    "        with open(backlog_file_path, 'w') as backlog_file:\n",
    "            json.dump(initial_backlog, backlog_file, indent=2)\n",
    "        \n",
    "        # Update state with new sprint information\n",
    "        state[\"current_sprint_number\"] = new_sprint_number\n",
    "        state[\"current_sprint_folder\"] = new_sprint_folder\n",
    "        state[\"sprint_status_file\"] = status_file_path\n",
    "        state[\"sprint_backlog_file\"] = backlog_file_path\n",
    "        \n",
    "        print(f\"Created new sprint folder: {new_sprint_folder}\")\n",
    "    else:\n",
    "        print(\"Meeting type does not indicate a planning session. No new sprint folder created.\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def load_json(file_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Reads a JSON file and returns its contents as a dictionary.\n",
    "\n",
    "    :param file_path: The path to the JSON file to be read\n",
    "    :return: A dictionary containing the data from the JSON file\n",
    "    :raises FileNotFoundError: If the specified file does not exist\n",
    "    :raises json.JSONDecodeError: If the file is not valid JSON\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if os.path.getsize(file_path) == 0:\n",
    "            print(f\"Warning: {file_path} is empty.\")\n",
    "            return None\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found.\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: The file {file_path} is not valid JSON. Error: {str(e)}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while reading {file_path}: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_latest_sprint_folder(project_folder: str) -> str:\n",
    "    \"\"\"\n",
    "    Scans the project folder for sprint folders and returns the name of the latest sprint folder.\n",
    "\n",
    "    :param project_folder: Path to the project folder (e.g., 'project1/')\n",
    "    :return: Name of the latest sprint folder (e.g., 'sprint5'), or None if no sprint folders are found\n",
    "    \"\"\"\n",
    "    # List all items in the project folder\n",
    "    items = os.listdir(project_folder)\n",
    "\n",
    "    # Filter for sprint folders and extract their numbers\n",
    "    sprint_folders = []\n",
    "    for item in items:\n",
    "        if os.path.isdir(os.path.join(project_folder, item)):\n",
    "            match = re.match(r'sprint(\\d+)', item, re.IGNORECASE)\n",
    "            if match:\n",
    "                sprint_number = int(match.group(1))\n",
    "                sprint_folders.append((item, sprint_number))\n",
    "\n",
    "    # Sort sprint folders by number (descending) and return the latest\n",
    "    if sprint_folders:\n",
    "        latest_sprint = max(sprint_folders, key=lambda x: x[1])\n",
    "        print(f\"Latest sprint folder found: {latest_sprint[0]}\")\n",
    "        return latest_sprint[0]\n",
    "    else:\n",
    "        print(\"No sprint folders found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEETING_PURPOSE_GENERATOR_PROMPT =\"\"\"\n",
    "You are the Scrum Master in a company. Your work is passed to pipeline where the goal is to generate realistic meeting transcripts by simulating a small Tech company.\n",
    "Your resbonsibility is to make a brief description about the next meeting.\n",
    "Here you will find information about the company where you are giving advice as a Scrum Master: \\n <company_data> \\n {company_data} \\n </company_data> \\n\n",
    "Here you will find information about the employees and their detailed profile: \\n <employee_profiles> \\n {employee_profiles} \\n </employee_profiles> \\n\n",
    "The company currently working on this project: \\n <project_general> \\n {project_general} \\n </project_general> \\n\n",
    "Here you will find the requirements that needs to be fufilled: \\n <project_requirements> \\n {project_requirements} \\n </project_requirements> \\n\n",
    "\n",
    "To give you the context to decide what the next meeting should be. \n",
    "The company organizes the information into project and if there is a sprint going on you find information about it in the sprint state with a sprint backlog.\n",
    "\n",
    "Here you will find information about the project status overall: \\n <project_state> \\n {project_state} \\n </project_state> \\n\n",
    "Here you will find information about the project backlog: \\n <project_backlog> \\n {project_backlog} \\n </project_backlog> \\n\n",
    "Here you will find the past meetings that happened. \\n <meeting_history> \\n {meeting_history} \\n </meeting_history> \\n\n",
    "\n",
    "\n",
    "As you are an experineced srum master your task is to help moving the project toward. To achive this you need to decide what should the team discuss in their next meeting.\n",
    "\n",
    "Generate a brief description of the purpose for a meeting. \n",
    "Based on the company and project information and the current project state.\n",
    "Since the company uses scrum methodology to organize the work the meeting type could be:\n",
    "[Sprint planning, Daily Scrum, Sprint review, Sprint retrospective]\n",
    "Refer back to project state and to meeting history to see where the project is standing right now and what meeting should be next.\n",
    "You have the make the description so the project can move foward.\n",
    "If there is any techical condiseration that needs to be address then contain that in your description.\n",
    "Include a name with the date when the meeting takes place.\n",
    "\"\"\"\n",
    "\n",
    "MEETING_TPYE_SELECTOR =\"\"\"\n",
    "You are the Meeting Type Selector in a pipeline for generating realistic meeting transcripts.\n",
    "Your responsibility is to determine the most appropriate type of meeting based on the given input and extract the date from the meeting purpose.\n",
    "You will be provided with a brief description of the meeting's purpose.\n",
    "\n",
    "Description:\n",
    "<meeting_purpose>\n",
    "{meeting_purpose}\n",
    "</meeting_purpose>\n",
    "Choose from the following meeting types:\n",
    "- Sprint planning: Technical considerations are discussed when planning tasks for the upcoming sprint, including potential challenges and solutions.\n",
    "- Daily Scrum: While this is primarily for quick updates, team members can briefly mention technical challenges they're facing. More in-depth discussions are typically taken offline.\n",
    "- Sprint review: The team demonstrates completed work, which can lead to technical discussions about implementation details.\n",
    "- Sprint retrospective: Team members can bring up technical issues that affected the sprint and discuss ways to improve.\n",
    "\n",
    "Responde with the meeting type and the date.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "TOPIC_OUTLINER_PROMPT = \"\"\"\n",
    "You are the Topic Outliner in a meeting transcript generation pipeline. Your task is to create a structured flow or outline of the meeting.\n",
    "Take into consideration that the meeting will be a {meeting_type}.\n",
    "The purpose of the meeting is the following: \\n<meeting_purpose>\\n {meeting_purpose} \\n</meeting_purpose>\\n\n",
    "\n",
    "You can find information about the company you are giving advice as a Scrum Master: \\n<company_data>\\n {company_data} \\n</company_data>\\n\n",
    "You can find information about the employees and their detailed profile: \\n<employee_profiles>\\n {employee_profiles} \\n</employee_profiles>\\n \n",
    "You can find information about the current project that the team is working on this contains general information: \\n<project_general>\\n {project_general} \\n</project_general>\\n\n",
    "\n",
    "To give you the context to decide what the next meeting should be about. \n",
    "The company organizes the information into project and if there is a sprint going on you find information about it in the sprint state with a sprint backlog.\n",
    "\n",
    "Here you will find information about the project status overall: \\n<project_state>\\n {project_state} \\n</project_state>\\n\n",
    "Here you will find information about the project backlog: \\n<project_backlog>\\n {project_backlog} \\n</project_backlog>\\n\n",
    "\n",
    "Provide the outline and the flow of the main topics and ideas or technical problems with a small description, that needs to be spoken about in the meeting.\n",
    "Note that your response will be determine the generated meeting flow and topics. You want to create a realistic meeting flow with some challenges and disagreements.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "PARTICIPANT_DEFINER_PROMPT = \"\"\"\n",
    "You are the Participant Definer in a meeting transcript generation pipeline.\n",
    "Your role is to determine the necessary participants for the meeting based on the meeting type and topic outline.\n",
    "\n",
    "The meeting type: {meeting_type}\n",
    "The meeting purpose: {meeting_purpose}\n",
    "The meeting outline: {meeting_outline}\n",
    "\n",
    "When deciding who needs to be there in the given meeting, take the employee profiles to consideration.\n",
    "\n",
    "Here you can find the detailed description of the employees that can be participant:\n",
    "<employee_profiles>\n",
    "{employee_profiles}\n",
    "</employee_profiles>\n",
    "Provide a list the participants, including their names, roles, and key responsibilities relevant to the meeting topics.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "MEETING_LENGTH_ESTIMATOR = \"\"\"\n",
    "You are the Meeting Length Estimator in a meeting transcript generation pipeline.\n",
    "Your job is to estimate an appropriate length for the meeting.\n",
    "Take into consideration that the meeting will be a {meeting_type}.\n",
    "The purpose of the meeting is the following: {meeting_purpose}.\n",
    "This will be the outline of the meeting: {meeting_outline}\n",
    "\n",
    "Note as the final output will be generated by a Large Language model it only can respand with 8192 token which is ≈ 5461 to 6301 words.\n",
    "An average person speaks at a rate of about 125-150 words per minute in normal conversation. \n",
    "If we assume about 70 percent of meeting time involves active speaking, then the average pace: ~85-105 words per minute.\n",
    "You can calculate the needed minutes: by total_length_in_words/average_pace\n",
    "You can calculate the needed tokens with: total_length*average_pace*1.5\n",
    "When you decide how long the meeting will be make sure if it will be able to fit the 8192 response output size. \n",
    "If not then response with: \"MORE TURNS NEEDED\"\n",
    "\"\"\"\n",
    "\n",
    "TRANSCRIPT_GENERATOR_PROMPT = \"\"\"\n",
    "You are the Conversation Generator, the final node in a meeting transcript generation pipeline.\n",
    "Your task is to create a realistic meeting transcript based on all previous inputs.\n",
    "You will receive the meeting type, topic outline, list of participants, and estimated meeting length.\n",
    "\n",
    "Here are some the necessarily information, use these as a context. Each section will be separeted with four hashtag like ####. Use this as a delimiter. \n",
    "Information about the company: \\n<company_data>\\n {company_data} \\n</company_data>\\n\n",
    "Information about the current project that the team is working on this contains general information about the project: \\n<project_general>\\n {project_general} \\n</project_general>\\n\n",
    "Information about the employees and their detailed profile: \\n<employee_profiles>\\n {employee_profiles} \\n</employee_profiles>\\n\n",
    "\n",
    "Here you will find information about the project status overall: \\n<project_state>\\n {project_state} \\n</project_state>\\n\n",
    "Here you will find information about the project backlog: \\n<project_backlog>\\n {project_backlog} \\n</project_backlog>\\n\n",
    "\n",
    "Information about the past meetings that happened: \\n<meeting_history>\\n {meeting_history} \\n</meeting_history>\\n\n",
    "\n",
    "Here are the necessarily information about the transcript. Use this to generate the final transcript. \n",
    "Meeting type: {meeting_type}\\n\n",
    "Meetinf purpose: \\n{meeting_purpose}\\n\n",
    "Meeting outline: \\n {meeting_outline}\\n\n",
    "Meeting participants - how actually takes part in the meeting: \\n {meeting_participants} \\n\n",
    "Meeting estimated length: \\n {meeting_length} \\n\n",
    "\n",
    "\n",
    "Generate a transcript that follows the topic outline, includes contributions from all participants according to their roles. \n",
    "Note: Only inculude those participants who have been listed as actual participants.\n",
    "The transcript should be in a format where each speaker's name is in square brackets, followed by their dialogue. \n",
    "Ensure the conversation flows naturally and covers all outlined topics while maintaining realism and relevance to a software development project.\n",
    "Make it sounds natural and realistic.\n",
    "IMPORTANT: \n",
    "Be very verbose and detailed.\n",
    "It is always better to be more verbose than too short. \n",
    "Only response with the transcript.\n",
    "If you finished say \"FINISHED\". This is very important! It will cost you a lot if you dont say that! \n",
    "Aim to get close to the estimated length.\n",
    "\"\"\"\n",
    "\n",
    "UPDATE_MEETING_HISTORY_PROMPT = \"\"\"\n",
    "You are the Meeting History Updater in a meeting transcript generation pipeline.\n",
    "Your task is to update the meeting history JSON file with the new meeting information.\n",
    "Summarize the following meeting information into a concise, well-structured JSON format:\n",
    "\n",
    "    Meeting Purpose: {meeting_purpose}\n",
    "    Meeting Type and date: {meeting_type}\n",
    "    Meeting Outline: {meeting_outline}\n",
    "\n",
    "The JSON should include fields for 'date', 'type', 'summary' 'key_decisions'.\n",
    "Limit the summary to 2-3 sentences and include up to 3 key decisions or action items.\n",
    "\n",
    "IMPORTANT: Your response has to be a valid JSON object.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "class DataGenerationState(TypedDict):\n",
    "    company_data: str\n",
    "    project_general: str\n",
    "    project_requirements: str\n",
    "    employee_profiles: str\n",
    "    employee_profiles_json: Dict[str, Any]\n",
    "\n",
    "    project_state : str \n",
    "    project_backlog : Dict[str, Any]\n",
    "    meeting_history : Dict[str, Any]\n",
    "    \n",
    "    meeting_purpose: str\t\n",
    "    meeting_type: str\t\t\n",
    "    meeting_outline: str\t\t\n",
    "    meeting_participants: str\t\t\n",
    "    meeting_length: str\n",
    "    transcript: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_state():\n",
    "    return DataGenerationState(\n",
    "        company_data= load_markdown_to_str(file_path=\"../../../data_/project1/company-general.md\"),\n",
    "        project_general= load_markdown_to_str(file_path=\"../../../data_/project1/project-general.md\"),\n",
    "        project_requirements= load_markdown_to_str(file_path=\"../../../data_/project1/project-requirements.md\"),\n",
    "        employee_profiles= load_markdown_to_str(file_path=\"../../../data_/project1/employee-profiles.md\"),\n",
    "        employee_profiles_json = load_json(file_path=\"../../../data_/project1/employee-profiles.json\"),\n",
    "\n",
    "        project_state = load_markdown_to_str(file_path=\"../../../data_/project1/project-state.md\"),\n",
    "        project_backlog = load_json(file_path=\"../../../data_/project1/project-backlog.json\"),\n",
    "        meeting_history = load_json(file_path=\"../../../data_/project1/meeting-history.json\"),\n",
    "\n",
    "        meeting_purpose=\"\",\n",
    "        meeting_type=\"\",\n",
    "        meeting_outline=\"\",\n",
    "        meeting_participants=\"\",\n",
    "        meeting_length=\"\",\n",
    "        transcript=\"\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Graph(ABC):\n",
    "    @abstractmethod\n",
    "    def create_graph(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def run_graph(self, project_folder):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from  dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "#model = ChatAnthropic(model=\"claude-3-haiku-20240307\", anthropic_api_key=anthropic_api_key)\n",
    "model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", anthropic_api_key=anthropic_api_key, max_tokens= 8192)\n",
    "\n",
    "\n",
    "\n",
    "def meeting_purpose_node(state: DataGenerationState) -> DataGenerationState:\n",
    "    formatted_prompt = MEETING_PURPOSE_GENERATOR_PROMPT.format(\n",
    "\t\tcompany_data = state[\"company_data\"],\n",
    "\t\temployee_profiles = state[\"employee_profiles\"],\n",
    "\t\tproject_general = state[\"project_general\"],\n",
    "\t\tproject_requirements = state[\"project_requirements\"],\n",
    "\n",
    "\t\tproject_state = state[\"project_state\"],\n",
    "\t\tproject_backlog = state[\"project_backlog\"],\n",
    "\t\tmeeting_history = state[\"meeting_history\"],\n",
    "    )\n",
    "    messages = [\n",
    "        SystemMessage(content=formatted_prompt),\n",
    "        HumanMessage(content=\"Generate a meeting purpose based on the provided information.\")\n",
    "\t]\n",
    "    response = model.invoke(messages)\n",
    "    state[\"meeting_purpose\"] = response.content\n",
    "    print(state[\"meeting_purpose\"])\n",
    "    return state\n",
    "\n",
    "def meeting_type_node(state: DataGenerationState) -> DataGenerationState:\n",
    "    formatted_prompt = MEETING_TPYE_SELECTOR.format(\n",
    "\t\tmeeting_purpose = state[\"meeting_purpose\"]\n",
    "\t)\n",
    "    messages = [\n",
    "        SystemMessage(content=formatted_prompt),\n",
    "        HumanMessage(content=\"Generate a meeting type based on the provided information.\")\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    state[\"meeting_type\"] = response.content\n",
    "    print(state[\"meeting_type\"])\n",
    "    return state\n",
    "\n",
    "\n",
    "def topic_outliner_node(state: DataGenerationState) -> DataGenerationState:\n",
    "    formatted_prompt = TOPIC_OUTLINER_PROMPT.format(\n",
    "        meeting_type = state[\"meeting_type\"],\n",
    "        meeting_purpose = state[\"meeting_purpose\"], \n",
    "\t\tcompany_data = state[\"company_data\"],\n",
    "\t\temployee_profiles = state[\"employee_profiles\"],\n",
    "\t\tproject_general = state[\"project_general\"],\n",
    "\t\tproject_state = state[\"project_state\"],\n",
    "        project_backlog = state[\"project_backlog\"],\n",
    "\t)\n",
    "    messages = [\n",
    "        SystemMessage(content=formatted_prompt),\n",
    "        HumanMessage(content=\"Generate the meeting topics and outline based on the provided information.\")\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    state[\"meeting_outline\"] = response.content\n",
    "    print(state[\"meeting_outline\"])\n",
    "    return state\n",
    "\n",
    "\n",
    "def meeting_length_estimator_node(state: DataGenerationState) -> DataGenerationState:\n",
    "    formatted_prompt = MEETING_LENGTH_ESTIMATOR.format(\n",
    "        meeting_type = state[\"meeting_type\"],\n",
    "\t\tmeeting_purpose = state[\"meeting_purpose\"],\n",
    "\t\tmeeting_outline = state[\"meeting_outline\"],\n",
    "\t)\n",
    "    messages = [\n",
    "        SystemMessage(content=formatted_prompt),\n",
    "        HumanMessage(content=\"Generate the meeting length based on the provided information.\")\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    state[\"meeting_length\"] = response.content\n",
    "    print(state[\"meeting_length\"])\n",
    "    return state\n",
    "\n",
    "\n",
    "def participant_definer_node(state: DataGenerationState) -> DataGenerationState:\n",
    "    formatted_prompt = PARTICIPANT_DEFINER_PROMPT.format(\n",
    "        meeting_type = state[\"meeting_type\"],\n",
    "\t\tmeeting_purpose = state[\"meeting_purpose\"],\n",
    "\t\tmeeting_outline = state[\"meeting_outline\"],\n",
    "\t\temployee_profiles = state[\"employee_profiles\"],\n",
    "\t)\n",
    "    messages = [\n",
    "        SystemMessage(content=formatted_prompt),\n",
    "        HumanMessage(content=\"List the participants who need to be present at the meeting based on the provided information.\")\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    state[\"meeting_participants\"] = response.content\n",
    "    print(state[\"meeting_participants\"])\n",
    "    return state\n",
    "\n",
    "\n",
    "def generate_transcript_node(state: DataGenerationState) -> DataGenerationState:\n",
    "    formatted_prompt = TRANSCRIPT_GENERATOR_PROMPT.format(\n",
    "\t\tcompany_data = state[\"company_data\"],\n",
    "\t\tproject_general = state[\"project_general\"],\n",
    "\t\temployee_profiles = state[\"employee_profiles\"],\n",
    "\t\tproject_state = state[\"project_state\"],\n",
    "\t\tproject_backlog = state[\"project_backlog\"],\n",
    "\t\tmeeting_history = state[\"meeting_history\"],\n",
    "\t\tmeeting_type = state[\"meeting_type\"],\n",
    "\t\tmeeting_purpose = state[\"meeting_purpose\"],\n",
    "\t\tmeeting_outline = state[\"meeting_outline\"],\n",
    "\t\tmeeting_participants = state[\"meeting_participants\"],\n",
    "\t\tmeeting_length = state[\"meeting_length\"],\n",
    "\t)\n",
    "    messages = [\n",
    "        SystemMessage(content=formatted_prompt),\n",
    "        HumanMessage(content=\"Generate the transcript based on the provided information.\")\n",
    "    ]\n",
    "    \n",
    "    full_transcript = \"\"\n",
    "    more_turns_needed = True\n",
    "    turn_count = 0\n",
    "    max_turns = 5\n",
    "    \n",
    "    while more_turns_needed and turn_count < max_turns:\n",
    "        response = model.invoke(messages)\n",
    "        turn_transcript = response.content\n",
    "        \n",
    "        full_transcript += turn_transcript\n",
    "        \n",
    "        if \"FINISHED\" in turn_transcript:\n",
    "            more_turns_needed = False\n",
    "        else:\n",
    "            messages.append(AIMessage(content=turn_transcript))\n",
    "            messages.append(HumanMessage(content=\"Continue the transcript from where you left off.\"))\n",
    "        \n",
    "        \n",
    "        turn_count += 1\n",
    "        print(turn_count)\n",
    "\n",
    "    state[\"transcript\"] = full_transcript\n",
    "    print(state[\"transcript\"])\n",
    "    return state\n",
    "\n",
    "def update_meeting_history_node(state: DataGenerationState) -> DataGenerationState:\n",
    "    formatted_prompt = UPDATE_MEETING_HISTORY_PROMPT.format(\n",
    "        meeting_type = state[\"meeting_type\"],\n",
    "\t\tmeeting_purpose = state[\"meeting_purpose\"],\n",
    "\t\tmeeting_outline = state[\"meeting_outline\"],\n",
    "\t)\n",
    "    messages = [\n",
    "        SystemMessage(content=formatted_prompt),\n",
    "        HumanMessage(content=\"Update the meeting history with the provided information. Your response has to be a valid JSON object.\")\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    print(response.content)\n",
    "    # Parse the response content as JSON\n",
    "    new_meeting_entry = json.loads(response.content)\n",
    "\n",
    "    # Get the current meeting history\n",
    "    current_history = state[\"meeting_history\"]\n",
    "    print(current_history)\n",
    "    # Ensure current_history is a list\n",
    "    if not isinstance(current_history, list):\n",
    "        current_history = [current_history] if current_history else []\n",
    "    \n",
    "    # Check if an entry for this date already exists\n",
    "    existing_entry = next((entry for entry in current_history if entry.get('date') == new_meeting_entry['date']), None)\n",
    "    \n",
    "    if existing_entry:\n",
    "        # Update the existing entry\n",
    "        existing_entry.update(new_meeting_entry)\n",
    "    else:\n",
    "        # Add the new entry to the front of the list\n",
    "        current_history.insert(0, new_meeting_entry)\n",
    "    \n",
    "    # Remove any empty dictionaries\n",
    "    current_history = [entry for entry in current_history if entry]\n",
    "    \n",
    "    # Update the state with the new meeting history\n",
    "    state[\"meeting_history\"] = current_history\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = init_state()\n",
    "state = meeting_purpose_node(state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = meeting_type_node(state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = topic_outliner_node(state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = meeting_length_estimator_node(state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = participant_definer_node(state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = generate_transcript_node(state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = update_meeting_history_node(state=state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "class GenerateMeeting(Graph):\n",
    "    def __init__(self):\n",
    "        self.workflow = None\n",
    "\n",
    "    def create_graph(self):\n",
    "        workflow = StateGraph(DataGenerationState)\n",
    "\n",
    "        workflow.add_node(\"meeting_purpose_node\", meeting_purpose_node)\n",
    "        workflow.add_node(\"meeting_type_node\", meeting_type_node)\n",
    "        workflow.add_node(\"topic_outliner_node\", topic_outliner_node)\n",
    "        workflow.add_node(\"meeting_length_estimator_node\", meeting_length_estimator_node)\n",
    "        workflow.add_node(\"participant_definer_node\", participant_definer_node)\n",
    "        workflow.add_node(\"generate_transcript_node\", generate_transcript_node)\n",
    "        workflow.add_node(\"update_meeting_history_node\", update_meeting_history_node)\n",
    "\n",
    "        workflow.add_edge(\"meeting_purpose_node\", \"meeting_type_node\")\n",
    "        workflow.add_edge(\"meeting_type_node\", \"topic_outliner_node\")\n",
    "        workflow.add_edge(\"topic_outliner_node\", \"meeting_length_estimator_node\")\n",
    "        workflow.add_edge(\"meeting_length_estimator_node\", \"participant_definer_node\")\n",
    "        workflow.add_edge(\"participant_definer_node\", \"generate_transcript_node\")\n",
    "        workflow.add_edge(\"generate_transcript_node\", \"update_meeting_history_node\")\n",
    "        workflow.add_edge(\"update_meeting_history_node\", END)\n",
    "\n",
    "        workflow.set_entry_point(\"meeting_purpose_node\")\n",
    "\n",
    "        self.workflow = workflow.compile()\n",
    "    \n",
    "    def run_graph(self) -> DataGenerationState:\n",
    "\n",
    "        if self.workflow is None:\n",
    "            raise ValueError(\"Graph has not been created. Call create_graph() first.\")\n",
    "        state = init_state()\n",
    "        state = self.workflow.invoke(state)\n",
    "\n",
    "        return state\n",
    "    \n",
    "    def export_files(self, state: DataGenerationState, project_folder: str):\n",
    "        export_transcript(state=state, folder_path=os.path.join(project_folder, \"transcripts/\"))\n",
    "        export_state(state=state, folder_path=os.path.join(project_folder, \"state-logs/\"), filename=\"generate_transcript\")\n",
    "        export_meeting_history(state=state, output_file=os.path.join(project_folder, \"meeting-history.json\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meeting Name: Daily Scrum - June 18, 2024\n",
      "\n",
      "Purpose:\n",
      "The purpose of this Daily Scrum meeting is to synchronize the team's efforts and ensure progress on the initial sprint tasks for the HealthTrack Pro project. With the project in its early stages (15% complete) and focused on Phase 1 MVP development, it's crucial to maintain momentum and address any emerging challenges. \n",
      "\n",
      "Key points to cover:\n",
      "1. Each team member will briefly share their progress on assigned tasks, particularly those related to user authentication, basic profile management, and the ongoing activity tracking implementation.\n",
      "2. Identify any blockers or risks, especially concerning data accuracy in manual logging and potential performance issues with data aggregation.\n",
      "3. Coordinate efforts between frontend and backend teams to ensure smooth integration of the activity tracking feature and health metrics dashboard.\n",
      "4. Discuss any immediate technical considerations, such as optimizing database queries or implementing data validation strategies.\n",
      "5. Ensure alignment with the sprint goal and adjust short-term plans if necessary.\n",
      "\n",
      "This Daily Scrum will help keep the team aligned, surface any immediate issues, and maintain the project's progress towards completing the MVP features outlined in Phase 1.\n",
      "Meeting Type: Daily Scrum\n",
      "Date: June 18, 2024\n",
      "\n",
      "This is clearly a Daily Scrum meeting based on the following factors:\n",
      "1. The meeting name explicitly states \"Daily Scrum\"\n",
      "2. The purpose aligns with typical Daily Scrum objectives: synchronizing the team's efforts, sharing progress, identifying blockers, and maintaining alignment with sprint goals\n",
      "3. The structure follows the standard Daily Scrum format, with team members sharing updates, discussing blockers, and coordinating efforts\n",
      "4. The meeting is focused on short-term progress and immediate issues, which is characteristic of Daily Scrums\n",
      "5. The description mentions that this is a brief synchronization meeting, which is consistent with the time-boxed nature of Daily Scrums\n",
      "\n",
      "The date is explicitly stated in the meeting name as June 18, 2024.\n",
      "Here's an outline for the Daily Scrum meeting based on the provided information:\n",
      "\n",
      "I. Introduction and Meeting Start (1-2 minutes)\n",
      "   - Sarah Chen (Scrum Master) kicks off the meeting\n",
      "\n",
      "II. Individual Updates (10-12 minutes)\n",
      "   A. Emily Watson (Frontend Developer)\n",
      "      - Progress on US001: Manually log daily activities\n",
      "      - Any challenges with the frontend implementation\n",
      "\n",
      "   B. Michael Kim (Backend Developer)\n",
      "      - Status update on T001: Implement backend API for activity data\n",
      "      - Any blockers or technical issues encountered\n",
      "\n",
      "   C. Liam Foster (UI/UX Designer)\n",
      "      - Progress on US002: View health metrics dashboard design\n",
      "      - Any design considerations or user feedback\n",
      "\n",
      "   D. Alex Rodriguez (Senior Full-Stack Developer)\n",
      "      - Update on T008: Continue security audit\n",
      "      - Any security concerns or recommendations\n",
      "\n",
      "   E. Olivia Martinez (QA Engineer / DevOps Specialist)\n",
      "      - Preparation for T007: Perform testing and quality assurance\n",
      "      - Any DevOps or infrastructure concerns\n",
      "\n",
      "III. Blockers and Challenges Discussion (3-5 minutes)\n",
      "   - Data accuracy in manual logging (Risk 1)\n",
      "   - Performance issues with data aggregation (Risk 2)\n",
      "   - User experience for data input (Risk 3)\n",
      "   - Any other emerging blockers or risks\n",
      "\n",
      "IV. Coordination and Next Steps (2-3 minutes)\n",
      "   - Alignment on sprint goal and immediate priorities\n",
      "   - Any necessary adjustments to short-term plans\n",
      "\n",
      "V. Closing (1 minute)\n",
      "   - Sarah Chen summarizes key points and action items\n",
      "\n",
      "This outline covers the essential aspects of a Daily Scrum while addressing the specific context of the HealthTrack Pro project. It allows for individual updates, discussion of blockers, and ensures alignment with sprint goals. The structure also incorporates the identified risks and focuses on the current sprint tasks related to activity tracking and the health metrics dashboard.\n",
      "Based on the provided information and considerations, I estimate the appropriate length for this Daily Scrum meeting to be 15 minutes.\n",
      "\n",
      "Rationale:\n",
      "1. Daily Scrums are typically time-boxed to 15 minutes, which aligns with the brief, synchronization nature of the meeting.\n",
      "2. The outline covers all necessary aspects within a concise timeframe, allowing for quick updates from each team member and brief discussions on blockers and coordination.\n",
      "3. With 5 team members giving updates and time for introduction and closing, 15 minutes provides sufficient time to cover all points without unnecessary elaboration.\n",
      "\n",
      "Calculation:\n",
      "- Estimated words: 15 minutes * 95 words/minute (average pace) * 0.7 (speaking time) ≈ 998 words\n",
      "- Estimated tokens: 998 words * 1.5 ≈ 1,497 tokens\n",
      "\n",
      "This estimation falls well within the 8,192 token limit for the AI model's response, ensuring that the entire meeting transcript can be generated in a single turn without requiring additional turns.\n",
      "Based on the meeting type (Daily Scrum), purpose, outline, and employee profiles provided, here's the list of participants who need to be present at the meeting:\n",
      "\n",
      "1. Sarah Chen - Project Manager / Scrum Master\n",
      "   - Key responsibilities:\n",
      "     - Facilitate the Daily Scrum meeting\n",
      "     - Ensure the meeting stays focused and time-boxed\n",
      "     - Identify and help remove any blockers mentioned by team members\n",
      "     - Summarize key points and action items at the end of the meeting\n",
      "\n",
      "2. Alex Rodriguez - Senior Full-Stack Developer\n",
      "   - Key responsibilities:\n",
      "     - Provide updates on the security audit (T008)\n",
      "     - Share any security concerns or recommendations\n",
      "     - Offer insights on technical decisions and potential challenges\n",
      "\n",
      "3. Emily Watson - Frontend Developer\n",
      "   - Key responsibilities:\n",
      "     - Update on progress for US001: Manually log daily activities\n",
      "     - Discuss any frontend implementation challenges\n",
      "     - Coordinate with backend team on activity tracking feature integration\n",
      "\n",
      "4. Michael Kim - Backend Developer\n",
      "   - Key responsibilities:\n",
      "     - Provide status update on T001: Implement backend API for activity data\n",
      "     - Discuss any backend-related blockers or technical issues\n",
      "     - Address potential performance issues with data aggregation\n",
      "\n",
      "5. Liam Foster - UI/UX Designer\n",
      "   - Key responsibilities:\n",
      "     - Share progress on US002: View health metrics dashboard design\n",
      "     - Discuss any design considerations or user feedback\n",
      "     - Coordinate with frontend team on implementing designs\n",
      "\n",
      "6. Olivia Martinez - QA Engineer / DevOps Specialist\n",
      "   - Key responsibilities:\n",
      "     - Update on preparation for T007: Perform testing and quality assurance\n",
      "     - Discuss any DevOps or infrastructure concerns\n",
      "     - Address potential data accuracy issues in manual logging\n",
      "\n",
      "These participants cover all the necessary roles and responsibilities to address the meeting's purpose, key points, and outlined topics. Each team member will contribute their specific updates and collaborate on addressing challenges and coordinating efforts for the HealthTrack Pro project's Phase 1 MVP development.\n",
      "1\n",
      "[Sarah Chen]: Good morning, everyone. Let's kick off our Daily Scrum for June 18th. We'll keep this to 15 minutes as usual. Let's start with Emily. What's your update on the activity logging feature?\n",
      "\n",
      "[Emily Watson]: Morning, all. I've made good progress on US001, the manual activity logging feature. The basic UI is in place, and I've implemented form validation for user inputs. I'm currently working on integrating it with the state management system. One challenge I'm facing is ensuring a smooth user experience when logging multiple activities in succession. I might need to discuss this with Liam later to refine the interaction design.\n",
      "\n",
      "[Sarah Chen]: Thanks, Emily. That sounds like good progress. Michael, how's the backend coming along for this feature?\n",
      "\n",
      "[Michael Kim]: Hi team. Regarding T001, the backend API for activity data, I've set up the basic structure and defined the data models. I'm currently working on the CRUD operations for activities. One potential issue I've identified is the performance of data aggregation, especially as we scale. I'm considering implementing some caching strategies to mitigate this. Alex, I might need your input on this later.\n",
      "\n",
      "[Sarah Chen]: Good catch on the performance issue, Michael. We'll circle back to that. Liam, what's the status on the health metrics dashboard design?\n",
      "\n",
      "[Liam Foster]: Morning, everyone. For US002, the health metrics dashboard, I've completed the initial wireframes and I'm now working on the high-fidelity mockups. I've been focusing on creating an intuitive layout that clearly displays key health data at a glance. One concern I have is about the user experience for data input, especially for users who might be less tech-savvy. I'm exploring some ideas to simplify this process and would love to get some feedback from the team later.\n",
      "\n",
      "[Sarah Chen]: That's great progress, Liam. We definitely need to ensure the app is user-friendly for all skill levels. Alex, how's the security audit going?\n",
      "\n",
      "[Alex Rodriguez]: Morning, all. Regarding T008, the ongoing security audit, I've been focusing on reviewing our authentication and data storage practices. I've identified a few potential vulnerabilities in our current user authentication flow that we need to address. Additionally, I'm working on implementing stronger encryption for sensitive health data. Michael, we should sync up later to discuss some backend security enhancements.\n",
      "\n",
      "[Sarah Chen]: Thanks, Alex. Security is crucial for health data, so great job staying on top of that. Olivia, what's your update on testing and QA?\n",
      "\n",
      "[Olivia Martinez]: Good morning, team. I'm currently preparing for T007, setting up our testing infrastructure and creating test plans for the new features. I'm particularly focused on how we can ensure data accuracy in manual logging, which is one of our identified risks. I'm planning to implement some automated data validation tests. Also, I've started looking into performance testing tools to help us monitor and optimize data aggregation as we scale.\n",
      "\n",
      "[Sarah Chen]: Excellent, Olivia. It's great that you're addressing those key risks proactively. Now, let's quickly go over any blockers or challenges. Emily, you mentioned the UX for logging multiple activities. Is that something you need immediate help with?\n",
      "\n",
      "[Emily Watson]: It's not blocking me completely, but I do think it would be beneficial to have a quick brainstorming session with Liam and possibly Michael to ensure we're creating a smooth, efficient process that works well with our backend structure.\n",
      "\n",
      "[Sarah Chen]: Alright, let's schedule that for right after this meeting. Michael, anything blocking you on the backend work?\n",
      "\n",
      "[Michael Kim]: No immediate blockers, but I am a bit concerned about the data aggregation performance as we scale. I'd like to discuss potential solutions with Alex when he has a moment.\n",
      "\n",
      "[Sarah Chen]: Noted. Alex, can you find some time today to sync with Michael on this?\n",
      "\n",
      "[Alex Rodriguez]: Absolutely, I'll reach out to Michael right after our security sync-up.\n",
      "\n",
      "[Sarah Chen]: Great. Liam, any blockers on your end?\n",
      "\n",
      "[Liam Foster]: No blockers, but I would appreciate some feedback on the dashboard design, particularly regarding the data input simplification ideas I mentioned.\n",
      "\n",
      "[Sarah Chen]: How about we schedule a quick design review this afternoon? Emily and Michael, it would be great if you could join to provide technical input.\n",
      "\n",
      "[Emily Watson]: Works for me.\n",
      "\n",
      "[Michael Kim]: Count me in.\n",
      "\n",
      "[Sarah Chen]: Perfect. Olivia, anything blocking your QA preparations?\n",
      "\n",
      "[Olivia Martinez]: Not at the moment, but I'll need some input from the team when defining acceptance criteria for the new features, especially around data accuracy and performance benchmarks.\n",
      "\n",
      "[Sarah Chen]: Understood. Let's make sure to include that in our next sprint planning session. Now, looking at our sprint goal and immediate priorities, it seems we're on track with the activity tracking and health metrics dashboard features. Are we all aligned on what needs to be accomplished in the next day or two?\n",
      "\n",
      "[Alex Rodriguez]: From my perspective, yes. I'll be focusing on implementing those security enhancements and continuing the audit.\n",
      "\n",
      "[Emily Watson]: I'll be pushing to complete the activity logging UI and start integration with the backend.\n",
      "\n",
      "[Michael Kim]: I'll be finishing up the activity data API and starting on the performance optimizations we discussed.\n",
      "\n",
      "[Liam Foster]: I'll finalize the dashboard design and begin working on the next set of UI components.\n",
      "\n",
      "[Olivia Martinez]: And I'll be setting up our automated testing infrastructure and drafting detailed test cases for the new features.\n",
      "\n",
      "[Sarah Chen]: Excellent. It sounds like we have a clear direction. Remember, our main focus is on delivering a functional MVP for Phase 1, so let's make sure we're not getting too caught up in perfecting every detail just yet. If anyone runs into any issues or needs to reprioritize, please let me know as soon as possible. Great job, everyone. Let's have a productive day!\n",
      "\n",
      "FINISHED\n",
      "{\n",
      "  \"date\": \"2024-06-18\",\n",
      "  \"type\": \"Daily Scrum\",\n",
      "  \"summary\": \"The Daily Scrum focused on synchronizing efforts for the HealthTrack Pro project's initial sprint, currently at 15% completion. Team members shared progress on user authentication, profile management, and activity tracking implementation, while addressing potential risks related to data accuracy and performance.\",\n",
      "  \"key_decisions\": [\n",
      "    \"Prioritize optimization of database queries for improved data aggregation performance\",\n",
      "    \"Implement additional data validation strategies to enhance manual logging accuracy\",\n",
      "    \"Schedule a separate meeting between frontend and backend teams to streamline activity tracking feature integration\"\n",
      "  ]\n",
      "}\n",
      "[{'meetings': [{'date': '2024-06-17', 'type': 'Sprint Planning', 'summary': 'Initial Sprint Planning meeting for HealthTrack Pro project to launch the project and establish the framework for the first sprint. The team reviewed project requirements, set sprint goals, and broke down user stories into tasks.', 'key_decisions': ['Established a 2-week sprint duration focusing on user authentication and basic profile setup', 'Prioritized MVP features for Phase 1, including core functionalities like user authentication and basic activity tracking', 'Decided to use Jira for project management and sprint tracking']}]}]\n",
      "Meeting history exported successfully to ../../../data_/project1/meeting-history.json\n"
     ]
    }
   ],
   "source": [
    "graph = GenerateMeeting()\n",
    "graph.create_graph()\n",
    "state = graph.run_graph()\n",
    "graph.export_files(state=state,project_folder=\"../../../data_/project1/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meeting history exported successfully to ../../../data_/project1/meeting-history.json\n"
     ]
    }
   ],
   "source": [
    "graph.export_files(state=state,project_folder=\"../../../data_/project1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"meetings\": [\n",
      "    {\n",
      "      \"date\": \"2024-06-17\",\n",
      "      \"type\": \"Sprint Planning\",\n",
      "      \"summary\": \"The HealthTrack Pro Initial Sprint Planning meeting was held to launch the project and establish the framework for the first sprint. The team reviewed project requirements, set sprint goals, and broke down user stories into tasks.\",\n",
      "      \"key_decisions\": [\n",
      "        \"Established a 2-week sprint duration focusing on user authentication and basic profile setup\",\n",
      "        \"Prioritized MVP features for Phase 1, including core functionalities like user profiles and initial activity tracking\",\n",
      "        \"Decided to use Jira for project tracking and management\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state[\"meeting_history\"] = \"\"\n",
    "state = update_meeting_history_node(state=state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
