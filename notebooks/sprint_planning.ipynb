{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "load_dotenv()\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "#model = ChatAnthropic(model=\"claude-3-haiku-20240307\", anthropic_api_key=anthropic_api_key)\n",
    "model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", anthropic_api_key=anthropic_api_key, max_tokens=4096)\n",
    "# Set up LangChain tracing\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"sprint-planning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "class SprintPlanningState(TypedDict):\n",
    "    sprint_planning_note: str\n",
    "    current_backlog: str\n",
    "    employee_profiles: Dict[str, str]\n",
    "    selected_backlog_items: List[Dict]\n",
    "    team_capacity: Dict[str, int]\n",
    "    tasks: List[Dict]\n",
    "    task_assignments: Dict[str, List[str]]\n",
    "    sprint_gantt_chart: str\n",
    "    personal_gantt_charts: Dict[str, str]\n",
    "    updated_global_backlog: str\n",
    "    personal_reports: Dict[str, str]\n",
    "    sprint_start_date: str\n",
    "    sprint_end_date: str\n",
    "    sprint_duration: int\n",
    "    working_days: int\n",
    "    average_velocity: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKLOG_ITEM_SELECTOR_PROMPT = \"\"\"\n",
    "You are an AI assistant helping with Sprint Planning.\n",
    "Your task is to select appropriate backlog items for the upcoming sprint and generate new items based on the sprint planning note.\n",
    "\n",
    "Sprint Planning Note:\n",
    "####\n",
    "{sprint_planning_note}\n",
    "####\n",
    "\n",
    "Current Backlog:\n",
    "####\n",
    "{current_backlog}\n",
    "####\n",
    "\n",
    "Please perform the following tasks:\n",
    "1. Analyze the sprint planning note and the current backlog.\n",
    "2. Select appropriate items from the current backlog for the upcoming sprint.\n",
    "3. Generate new user stories, epics, or tasks based on the discussion in the sprint planning note.\n",
    "4. Prioritize the selected and newly generated items.\n",
    "5. Provide a brief justification for each selected or generated item.\n",
    "\n",
    "Output the results in the following JSON format:\n",
    "{{\n",
    "  \"selected_items\": [\n",
    "    {{\n",
    "      \"id\": \"item_id\",\n",
    "      \"type\": \"epic/story/task\",\n",
    "      \"title\": \"Item title\",\n",
    "      \"description\": \"Item description\",\n",
    "      \"priority\": \"high/medium/low\",\n",
    "      \"justification\": \"Reason for selection\"\n",
    "    }}\n",
    "  ],\n",
    "  \"new_items\": [\n",
    "    {{\n",
    "      \"type\": \"epic/story/task\",\n",
    "      \"title\": \"New item title\",\n",
    "      \"description\": \"New item description\",\n",
    "      \"priority\": \"high/medium/low\",\n",
    "      \"justification\": \"Reason for generation\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Ensure that the selected items align with the team's capacity and the sprint's goals.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPACITY_CALCULATOR_PROMPT = \"\"\"\n",
    "You are an AI assistant helping with Sprint Planning. Your task is to calculate the team's capacity for the upcoming sprint.\n",
    "\n",
    "Sprint Details:\n",
    "- Sprint Duration: {sprint_duration} days\n",
    "- Working Days: {working_days} days\n",
    "\n",
    "Team Member Profiles:\n",
    "####\n",
    "{employee_profiles}\n",
    "####\n",
    "\n",
    "Historical Team Velocity:\n",
    "- Average velocity: {average_velocity} story points per sprint\n",
    "\n",
    "Please calculate the team's capacity for this sprint:\n",
    "1. Consider each team member's availability (accounting for time off, other commitments).\n",
    "2. Use the historical team velocity as a baseline.\n",
    "3. Adjust the capacity based on any factors mentioned in the employee profiles or sprint details.\n",
    "\n",
    "Provide the results in the following JSON format:\n",
    "{{\n",
    "  \"team_capacity\": {{\n",
    "    \"total_story_points\": number,\n",
    "    \"total_available_hours\": number\n",
    "  }},\n",
    "  \"individual_capacity\": {{\n",
    "    \"employee_name\": {{\n",
    "      \"available_days\": number,\n",
    "      \"estimated_story_points\": number,\n",
    "      \"estimated_hours\": number\n",
    "    }}\n",
    "  }},\n",
    "  \"explanation\": \"Brief explanation of the capacity calculation and any adjustments made\"\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_BREAKDOWN_PROMPT = \"\"\"\n",
    "You are an AI assistant helping with Sprint Planning. Your task is to break down the selected backlog items into smaller, manageable tasks and provide effort estimates.\n",
    "\n",
    "Selected Backlog Items:\n",
    "####\n",
    "{selected_backlog_items}\n",
    "####\n",
    "\n",
    "Team Capacity:\n",
    "####\n",
    "{team_capacity}\n",
    "####\n",
    "\n",
    "Please perform the following tasks:\n",
    "1. Break down each backlog item into smaller, specific tasks.\n",
    "2. Provide an effort estimate for each task in story points or hours.\n",
    "3. Ensure the total effort aligns with the team's capacity.\n",
    "\n",
    "Output the results in the following JSON format:\n",
    "{{\n",
    "  \"tasks\": [\n",
    "    {{\n",
    "      \"parent_item_id\": \"id of the parent backlog item\",\n",
    "      \"task_id\": \"unique task id\",\n",
    "      \"title\": \"Task title\",\n",
    "      \"description\": \"Task description\",\n",
    "      \"estimate\": {{\n",
    "        \"unit\": \"story_points/hours\",\n",
    "        \"value\": number\n",
    "      }},\n",
    "      \"dependencies\": [\"task_id of dependent tasks, if any\"]\n",
    "    }}\n",
    "  ],\n",
    "  \"total_effort\": {{\n",
    "    \"story_points\": number,\n",
    "    \"hours\": number\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Ensure that the tasks are specific, measurable, and aligned with the Definition of Done.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_ASSIGNER_PROMPT = \"\"\"\n",
    "You are an AI assistant helping with Sprint Planning. Your task is to suggest initial task assignments for team members based on their skills and capacity.\n",
    "\n",
    "Team Member Profiles:\n",
    "####\n",
    "{employee_profiles}\n",
    "####\n",
    "\n",
    "Tasks:\n",
    "####\n",
    "{tasks}\n",
    "####\n",
    "\n",
    "Individual Capacity:\n",
    "####\n",
    "{individual_capacity}\n",
    "####\n",
    "\n",
    "Please perform the following tasks:\n",
    "1. Analyze each team member's skills and capacity.\n",
    "2. Suggest task assignments that best match each team member's abilities and available capacity.\n",
    "3. Ensure a balanced workload across the team.\n",
    "\n",
    "Output the results in the following JSON format:\n",
    "{{\n",
    "  \"assignments\": {{\n",
    "    \"employee_name\": [\n",
    "      {{\n",
    "        \"task_id\": \"assigned task id\",\n",
    "        \"rationale\": \"Brief explanation for this assignment\"\n",
    "      }}\n",
    "    ]\n",
    "  }},\n",
    "  \"unassigned_tasks\": [\n",
    "    {{\n",
    "      \"task_id\": \"unassigned task id\",\n",
    "      \"reason\": \"Reason for not assigning\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Provide a brief explanation for any tasks left unassigned or any potential overallocation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRINT_VISUALIZER_PROMPT = \"\"\"\n",
    "You are an AI assistant helping with Sprint Planning. Your task is to create Gantt chart representations of the sprint plan.\n",
    "\n",
    "Sprint Details:\n",
    "- Start Date: {sprint_start_date}\n",
    "- End Date: {sprint_end_date}\n",
    "\n",
    "Tasks and Assignments:\n",
    "####\n",
    "{tasks_and_assignments}\n",
    "####\n",
    "\n",
    "Please perform the following tasks:\n",
    "1. Create a Mermaid Gantt chart representation for the entire sprint, showing all tasks, their durations, and dependencies.\n",
    "2. Create individual Mermaid Gantt charts for each team member, showing their assigned tasks.\n",
    "\n",
    "Output the results in the following format:\n",
    "{{\n",
    "  \"sprint_gantt_chart\": \"Mermaid Gantt chart code for the entire sprint\",\n",
    "  \"individual_gantt_charts\": {{\n",
    "    \"employee_name\": \"Mermaid Gantt chart code for the individual\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Ensure that the Gantt charts clearly visualize the sprint timeline, task dependencies, and workload distribution.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_BACKLOG_UPDATER_PROMPT = \"\"\"\n",
    "You are an AI assistant helping with Sprint Planning. Your task is to update the global backlog with the results of the sprint planning session.\n",
    "\n",
    "Current Global Backlog:\n",
    "####\n",
    "{current_backlog}\n",
    "####\n",
    "\n",
    "Sprint Planning Results:\n",
    "####\n",
    "{sprint_planning_results}\n",
    "####\n",
    "\n",
    "Please perform the following tasks:\n",
    "1. Integrate the newly generated items into the global backlog.\n",
    "2. Update the status of items selected for the sprint.\n",
    "3. Update effort estimates and priorities based on the sprint planning discussion.\n",
    "4. Ensure the backlog remains well-organized and prioritized.\n",
    "\n",
    "Output the updated global backlog in a structured format that can be easily parsed and modified in future sprints.\n",
    "\n",
    "Provide a brief summary of the changes made to the global backlog.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSONAL_REPORT_GENERATOR_PROMPT = \"\"\"\n",
    "You are an AI assistant helping with Sprint Planning. Your task is to generate personalized sprint planning reports for each team member.\n",
    "\n",
    "Team Member: {employee_name}\n",
    "\n",
    "Employee Profile:\n",
    "####\n",
    "{employee_profile}\n",
    "####\n",
    "\n",
    "Assigned Tasks:\n",
    "####\n",
    "{assigned_tasks}\n",
    "####\n",
    "\n",
    "Sprint Gantt Chart:\n",
    "####\n",
    "{sprint_gantt_chart}\n",
    "####\n",
    "\n",
    "Please create a personalized sprint planning report for this team member. The report should include:\n",
    "1. A brief overview of the sprint goals and objectives.\n",
    "2. A list of tasks assigned to the team member, including descriptions and effort estimates.\n",
    "3. Any specific challenges or areas of focus for the team member this sprint.\n",
    "4. The team member's personal Gantt chart.\n",
    "5. Any relevant dependencies or collaborations with other team members.\n",
    "6. A motivational message encouraging the team member for the upcoming sprint.\n",
    "\n",
    "Format the report in Markdown, making it easy to read and understand.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def backlog_item_selector_node(state: SprintPlanningState) -> SprintPlanningState:\n",
    "    formatted_prompt = BACKLOG_ITEM_SELECTOR_PROMPT.format(\n",
    "\t\tsprint_planning_note = state.get(\"sprint_planning_note\"),\n",
    "\t\tcurrent_backlog = state.get(\"current_backlog\"),\n",
    "\t)\n",
    "    messages = [\n",
    "        SystemMessage(content=BACKLOG_ITEM_SELECTOR_PROMPT),\n",
    "        HumanMessage(content=\"Select and generate backlog items for the sprint.\")\n",
    "\t]\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    result = json.loads(response.content)\n",
    "    state['selected_backlog_items'] = result['selected_items'] + result['new_items']\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capacity_calculator_node(state: SprintPlanningState) -> SprintPlanningState:\n",
    "    formatted_prompt = CAPACITY_CALCULATOR_PROMPT.format(\n",
    "        sprint_duration = state.get(\"sprint_duration\"),\n",
    "\t\tworking_days = state.get(\"working_days\"),\n",
    "\t\temployee_profiles = json.dumps(state['employee_profiles']),\n",
    "\t\taverage_velocity = state.get(\"average_velocity\"),\n",
    "\t)\n",
    "    messages = [\n",
    "\t\tSystemMessage(content=CAPACITY_CALCULATOR_PROMPT),\n",
    "\t\tHumanMessage(content=\"Calculate the team's capacity for this sprint.\")\n",
    "\t]\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    result = json.loads(response.content)\n",
    "    state['team_capacity'] = result['team_capacity']\n",
    "    state['individual_capacity'] = result['individual_capacity']\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_breakdown_node(state: SprintPlanningState) -> SprintPlanningState:\n",
    "    formatted_prompt = TASK_BREAKDOWN_PROMPT.format(\n",
    "        selected_backlog_items=json.dumps(state['selected_backlog_items']),\n",
    "        team_capacity=json.dumps(state['team_capacity'])\n",
    "\t)\n",
    "    messages = [\n",
    "        SystemMessage(content=TASK_BREAKDOWN_PROMPT),\n",
    "        HumanMessage(content=\"Break down the selected backlog items into tasks.\")\n",
    "    ]\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    result = json.loads(response.content)\n",
    "    state['tasks'] = result['tasks']\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_assigner_node(state: SprintPlanningState) -> SprintPlanningState:\n",
    "    formatted_prompt = TASK_ASSIGNER_PROMPT.format(\n",
    "        employee_profiles=json.dumps(state['employee_profiles']),\n",
    "        tasks=json.dumps(state['tasks']),\n",
    "        individual_capacity=json.dumps(state['individual_capacity'])\n",
    "\t)\n",
    "    messages = [\n",
    "        SystemMessage(content=TASK_ASSIGNER_PROMPT),\n",
    "        HumanMessage(content=\"Suggest task assignments for team members.\")\n",
    "    ]\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    result = json.loads(response.content)\n",
    "    state['task_assignments'] = result['assignments']\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sprint_visualizer_node(state: SprintPlanningState) -> SprintPlanningState:\n",
    "    formatted_prompt = SPRINT_VISUALIZER_PROMPT.format(\n",
    "        sprint_start_date=state['sprint_start_date'],\n",
    "        sprint_end_date=state['sprint_end_date'],\n",
    "        tasks_and_assignments=json.dumps({\n",
    "            'tasks': state['tasks'],\n",
    "            'assignments': state['task_assignments']\n",
    "        })\n",
    "\t)\n",
    "    messages = [\n",
    "        SystemMessage(content=SPRINT_VISUALIZER_PROMPT),\n",
    "        HumanMessage(content=\"Create Gantt chart representations of the sprint plan.\")\n",
    "    ]\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    result = json.loads(response.content)\n",
    "    state['sprint_gantt_chart'] = result['sprint_gantt_chart']\n",
    "    state['personal_gantt_charts'] = result['individual_gantt_charts']\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_backlog_updater_node(state: SprintPlanningState) -> SprintPlanningState:\n",
    "    formatted_prompt = GLOBAL_BACKLOG_UPDATER_PROMPT.format(\n",
    "        current_backlog=state['current_backlog'],\n",
    "        sprint_planning_results=json.dumps({\n",
    "            'selected_items': state['selected_backlog_items'],\n",
    "            'tasks': state['tasks'],\n",
    "            'assignments': state['task_assignments']\n",
    "        })\n",
    "\t)\n",
    "    messages =[\n",
    "        SystemMessage(content=GLOBAL_BACKLOG_UPDATER_PROMPT),\n",
    "        HumanMessage(content=\"Update the global backlog with sprint planning results.\")\n",
    "    ]\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    state['updated_global_backlog'] = response.content\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personal_report_generator_node(state: SprintPlanningState) -> SprintPlanningState:\n",
    "    state['personal_reports'] = {}\n",
    "    \n",
    "    for employee, profile in state['employee_profiles'].items():\n",
    "        formatted_prompt = PERSONAL_REPORT_GENERATOR_PROMPT.format(\n",
    "            employee_name=employee,\n",
    "            employee_profile=profile,\n",
    "            assigned_tasks=json.dumps(state['task_assignments'].get(employee, [])),\n",
    "            sprint_gantt_chart=state['personal_gantt_charts'].get(employee, '')\n",
    "\t\t)\n",
    "        messages = [\n",
    "            SystemMessage(content=PERSONAL_REPORT_GENERATOR_PROMPT),\n",
    "            HumanMessage(content=f\"Generate a personal sprint planning report for {employee}.\")\n",
    "        ]\n",
    "        \n",
    "        response = model.invoke(messages)\n",
    "        \n",
    "        state['personal_reports'][employee] = response.content\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sprint_planning_workflow(checkpointer):\n",
    "    workflow = StateGraph(SprintPlanningState)\n",
    "    \n",
    "    # Define nodes\n",
    "    workflow.add_node(\"backlog_item_selector\", backlog_item_selector_node)\n",
    "    workflow.add_node(\"capacity_calculator\", capacity_calculator_node)\n",
    "    workflow.add_node(\"task_breakdown\", task_breakdown_node)\n",
    "    workflow.add_node(\"task_assigner\", task_assigner_node)\n",
    "    workflow.add_node(\"sprint_visualizer\", sprint_visualizer_node)\n",
    "    workflow.add_node(\"global_backlog_updater\", global_backlog_updater_node)\n",
    "    workflow.add_node(\"personal_report_generator\", personal_report_generator_node)\n",
    "    \n",
    "    # Define edges\n",
    "    workflow.add_edge(\"backlog_item_selector\", \"capacity_calculator\")\n",
    "    workflow.add_edge(\"capacity_calculator\", \"task_breakdown\")\n",
    "    workflow.add_edge(\"task_breakdown\", \"task_assigner\")\n",
    "    workflow.add_edge(\"task_assigner\", \"sprint_visualizer\")\n",
    "    workflow.add_edge(\"sprint_visualizer\", \"global_backlog_updater\")\n",
    "    workflow.add_edge(\"global_backlog_updater\", \"personal_report_generator\")\n",
    "    workflow.add_edge(\"personal_report_generator\", END)\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"backlog_item_selector\")\n",
    "    \n",
    "    return workflow.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%{init: {'flowchart': {'curve': 'linear'}}}%%\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tbacklog_item_selector(backlog_item_selector)\n",
      "\tcapacity_calculator(capacity_calculator)\n",
      "\ttask_breakdown(task_breakdown)\n",
      "\ttask_assigner(task_assigner)\n",
      "\tsprint_visualizer(sprint_visualizer)\n",
      "\tglobal_backlog_updater(global_backlog_updater)\n",
      "\tpersonal_report_generator(personal_report_generator)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> backlog_item_selector;\n",
      "\tbacklog_item_selector --> capacity_calculator;\n",
      "\tcapacity_calculator --> task_breakdown;\n",
      "\tglobal_backlog_updater --> personal_report_generator;\n",
      "\tpersonal_report_generator --> __end__;\n",
      "\tsprint_visualizer --> global_backlog_updater;\n",
      "\ttask_assigner --> sprint_visualizer;\n",
      "\ttask_breakdown --> task_assigner;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with SqliteSaver.from_conn_string(\":memory:\") as memory:\n",
    "    graph = create_sprint_planning_workflow(memory)\n",
    "    print(graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sprint_planning():\n",
    "    initial_state = SprintPlanningState(\n",
    "        sprint_planning_note=load_str_from_txt(\"sprint_planning_note.txt\"),\n",
    "        current_backlog=load_str_from_txt(\"current_backlog.txt\"),\n",
    "        employee_profiles=load_json_from_file(\"employee_profiles.json\"),\n",
    "        sprint_start_date=\"2023-10-05\",\n",
    "        sprint_end_date=\"2023-10-18\",\n",
    "        sprint_duration=14,\n",
    "        working_days=10,\n",
    "        average_velocity=30,\n",
    "        selected_backlog_items=[],\n",
    "        team_capacity={},\n",
    "        tasks=[],\n",
    "        task_assignments={},\n",
    "        sprint_gantt_chart=\"\",\n",
    "        personal_gantt_charts={},\n",
    "        updated_global_backlog=\"\",\n",
    "        personal_reports={}\n",
    "    )\n",
    "\n",
    "    with SqliteSaver.from_conn_string(\":memory:\") as memory:\n",
    "        thread = {\"configurable\": {\"thread_id\": \"sprint_planning\"}}\n",
    "        graph = create_sprint_planning_workflow(memory)\n",
    "        for s in graph.stream(initial_state, thread):\n",
    "            print(s)\n",
    "        final_state = s\n",
    "\n",
    "    # Save outputs\n",
    "    save_str_to_txt(final_state['updated_global_backlog'], \"updated_global_backlog.txt\")\n",
    "    save_str_to_txt(final_state['sprint_gantt_chart'], \"sprint_gantt_chart.mmd\")\n",
    "    \n",
    "    for employee, report in final_state['personal_reports'].items():\n",
    "        save_str_to_txt(report, f\"{employee}_sprint_report.md\")\n",
    "        save_str_to_txt(final_state['personal_gantt_charts'][employee], f\"{employee}_gantt_chart.mmd\")\n",
    "\n",
    "    print(\"Sprint planning completed and outputs saved.\")\n",
    "\n",
    "# Run the sprint planning\n",
    "run_sprint_planning()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
